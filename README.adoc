= TalkToMeCPP - A proof of concept barebones C++ client for Voxta

_Made in collaboration with https://twitter.com/DZnnah[DZnnah]_

== Dev Progress

:uri-qg-status: https://sonarcloud.io/dashboard?id=grrimgrriefer_TalkToMeCPP
:img-qg-status: https://sonarcloud.io/api/project_badges/measure?project=grrimgrriefer_TalkToMeCPP&metric=alert_status
:uri-build-status: https://github.com/grrimgrriefer/TalkToMeCPP/actions/workflows/msbuild.yml
:img-build-status: https://github.com/grrimgrriefer/TalkToMeCPP/actions/workflows/msbuild.yml/badge.svg

image:{img-build-status}[Build Status, link={uri-build-status}]
image:{img-qg-status}[Quality Gate Status,link={uri-qg-status}]

*This project is analysed on https://sonarcloud.io/project/overview?id=grrimgrriefer_TalkToMeCPP[SonarCloud]!*

[ :heavy_check_mark: ]   Authenticate to Voxta server

[ :heavy_check_mark: ]   Load characters

[ :heavy_check_mark:	]   Text chat with specific character(s)

[ :heavy_check_mark:		]   Full code cleanup & proper test coverage 

[ :fire:	]   Playback Voxta server generated audio

[ :black_square_button:	]   Provide Mic input to Voxta server

[ :black_square_button:		]   Full code cleanup & proper test coverage 


== Build

Either

* Download the x64 windows .zip from latest workflow run: https://github.com/grrimgrriefer/TalkToMeCPP/actions

OR

* Build it yourself 
** reqs:
*** MSbuild with C++20 support (VS 2019 v16.9 or later)
*** Activated vcpkg to install the req libs (classic mode, *not* manifest mode)

*Note:* _I only target x64, so the x86 may or may not work._ :shrug:
  
== Run

1. Run Voxta.Server.Exe (v1.0.0-beta.116)
  - Download from https://voxta.ai/
  - Ensure a valid Voxta service configuration (TTS, STT, LLM)
2. Run TalkToMeCPP.exe
3. Enjoy :3

== Q&A

[qanda]
Can I use this for my own project?:: Yes.
Do I need to credit you?:: We'd appreciate it, but if you don't that's fine too. :shrug:
Can I contribute to this repo?:: No.
Can I donate/support this?:: No.  _(irl job exclusivity clause)_