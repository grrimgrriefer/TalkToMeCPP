= TalkToMeCPP - A proof of concept barebones C++ client for Voxta

_All of this is CC0 cuz no way am I gonna hire a lawyer for this project lmao._

== Dev Progress

:uri-qg-status: https://sonarcloud.io/dashboard?id=justanotherburner123_TalkToMeCPP
:img-qg-status: https://sonarcloud.io/api/project_badges/measure?project=justanotherburner123_TalkToMeCPP&metric=alert_status
:uri-build-status: https://github.com/justanotherburner123/TalkToMeCPP/actions/workflows/msbuild.yml
:img-build-status: https://github.com/justanotherburner123/TalkToMeCPP/actions/workflows/msbuild.yml/badge.svg

image:{img-build-status}[Build Status, link={uri-build-status}]
image:{img-qg-status}[Quality Gate Status,link={uri-qg-status}]

[ :heavy_check_mark: ]   Authenticate to Voxta server

[ :heavy_check_mark: ]   Load characters

[ :fire:	]   Text chat with specific character(s)

[ :black_square_button:	]   Playback Voxta server generated audio

[ :black_square_button:	]   Provide Mic input to Voxta server

== Build

- Download the x64 windows build from latest run artifacts: https://github.com/justanotherburner123/TalkToMeCPP/actions
- Build it yourself 
  * reqs:
  ** Compiler with C++20 support
  ** Activated vcpkg to install the req libs
  
[NOTE]
====
*NOTE* _x86 builds might work but I cba to test two versions, so who knows._ :shrug:
====
  
== Run

Reqs
- Voxta server (from https://voxta.ai/)
- Valid Voxta service configuration (TTS, STT, LLM)

1. Run Voxta.Server.Exe 
2. Run TalkToMeCPP.exe
3. Enjoy :3
