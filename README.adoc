= TalkToMeCPP - A proof of concept barebones C++ client for Voxta

== Dev Progress

:uri-qg-status: https://sonarcloud.io/dashboard?id=grrimgrriefer_TalkToMeCPP
:img-qg-status: https://sonarcloud.io/api/project_badges/measure?project=grrimgrriefer_TalkToMeCPP&metric=alert_status
:uri-build-status: https://github.com/grrimgrriefer/TalkToMeCPP/actions/workflows/msbuild.yml
:img-build-status: https://github.com/grrimgrriefer/TalkToMeCPP/actions/workflows/msbuild.yml/badge.svg

image:{img-build-status}[Build Status, link={uri-build-status}]
image:{img-qg-status}[Quality Gate Status,link={uri-qg-status}]

*This project is analysed on https://sonarcloud.io/project/overview?id=grrimgrriefer_TalkToMeCPP[SonarCloud]!*

[ :heavy_check_mark: ]   Authenticate to Voxta server

[ :heavy_check_mark: ]   Load characters

[ :fire:	]   Text chat with specific character(s)

[ :black_square_button:	]   Playback Voxta server generated audio

[ :black_square_button:	]   Provide Mic input to Voxta server

== Build

Either

* Download the x64 windows build from latest run artifacts: https://github.com/grrimgrriefer/TalkToMeCPP/actions

OR

* Build it yourself 
** reqs:
*** MSbuild with C++20 support (VS 2019 v16.9 or later)
*** Activated vcpkg to install the req libs (classic mode, *not* manifest mode)
  
*Note:* _I only tested x64, so the x86 may or may not work._ :shrug:
  
== Run

1. Run Voxta.Server.Exe 
  - Download from https://voxta.ai/
  - Ensure a valid Voxta service configuration (TTS, STT, LLM)
2. Run TalkToMeCPP.exe
3. Enjoy :3

== Q&A

[qanda]
Can I use this for my own project?:: Yes.
Do I need to credit you?:: No.
Can I contribute to this repo?:: No.
Can I donate/support this?:: No. _(IRL job exclusivity clause)_